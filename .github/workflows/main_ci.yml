name: CI DST Airlines - Full Infrastructure

on:
  push:
    branches: [ main, master, refactoring ]
  pull_request:
    branches: [ main, master, refactoring ]

jobs:
  # JOB 1 : Tests API (Python + Postgres)
  api-tests:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_USER: user_test
          POSTGRES_PASSWORD: password_test
          POSTGRES_DB: db_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest httpx
          if [ -f api/requirements.txt ]; then pip install -r api/requirements.txt; fi
      - name: Run API Unit Tests
        env:
          POSTGRES_HOST: localhost
          POSTGRES_PORT: 5432
          POSTGRES_USER: user_test
          POSTGRES_PASSWORD: password_test
          POSTGRES_DB: db_test
        run: |
          export PYTHONPATH=$PYTHONPATH:$(pwd)
          python -m pytest -v api/tests/test_api.py

  # JOB 2 : Validation Terraform (Infrastructure & Volumes)
  terraform-quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0
      - name: Terraform Init
        run: terraform init
        working-directory: ./terraform
      - name: Terraform Validate
        run: terraform validate
        working-directory: ./terraform
      - name: Terraform Format Check
        run: terraform fmt -check
        working-directory: ./terraform

  # JOB 3 : Validation de TOUS les DAGs (ETL + ML) et Plugins
  # Vérifie que les fichiers dans airflow/dags sont syntaxiquement corrects et importables
  airflow-validation:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install Airflow, Providers & ML Deps
        run: |
          python -m pip install --upgrade pip
          # Installation des librairies pour l'ETL (Providers) et le ML
          pip install apache-airflow \
                      apache-airflow-providers-postgres \
                      apache-airflow-providers-http \
                      apache-airflow-providers-common-sql \
                      pandas pyarrow mlflow scikit-learn requests selenium
      - name: Static DAG Load Test (ETL + ML)
        run: |
          # Simulation du PYTHONPATH pour inclure les plugins
          export PYTHONPATH=$PYTHONPATH:$(pwd)/airflow/plugins
          # Scan de tout le dossier dags pour détecter d'éventuelles ImportErrors
          python -c "from airflow.models import DagBag; dagbag = DagBag(dag_folder='airflow/dags', include_examples=False); print('Import Errors Found:', dagbag.import_errors); exit(1 if len(dagbag.import_errors) > 0 else 0)"

  # JOB 4 : Vérification du Build Docker (Dry Run)
  # Garantit que les modifications dans requirements.txt ne cassent pas le build
  docker-build-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Validate Docker Compose Config
        run: docker compose config
      - name: Build Airflow Images (Dry Run)
        # On build le service de base pour valider les dépendances système et pip
        run: docker compose build airflow-init